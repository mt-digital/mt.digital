<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Matthew Turner" />
  <title>Tononi’s IIT and Searle’s Chinese Room</title>
  <style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
          href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.4/css/bootstrap.min.css"
          integrity="2hfp1SzUoho7/TsGGGDaFdsuuDL0LX2hnUp6VkX3CUQ2K4K+xjboZdsXyp4oUHZj"
          crossorigin="anonymous">
</head>
<body>
<div class="container">
    <div id="header">
    <h1 class="title">Tononi’s integrated information theory (IIT) and Searle’s Chinese Room</h1>
    <br>
    <h2 class="author">Matthew Turner</h2>
    <h3 class="date">September 7, 2016</h3>
    <a href="/">Go back</a>
    </div>
    <br>
    <hr>
    <br>
    <h1 id="in-defense-of-the-chinese-room"><span class="header-section-number">1</span> In Defense of the Chinese Room</h1>
    <p>The Chinese Room part of the paper is only a few paragraphs out of 19 pages of solid text. In Searle’s words, the paper advances the argument that</p>
    <b><i>
    <p>only a machine could think, and only very special kinds of machines, namely brains and machines with internal causal powers equivalent to those of brains. And that is why strong AI has little to tell us about thinking, since it is not about machines but about programs, and no program by itself is sufficient for thinking.</p>
    </i></b>
    <p>In other words, syntax is not semantics. However this does imply that if only the right hardware could be built and the correct software to be written, then the machinery itself could be stimulated to a dance of consciousness. <span class="citation">J. R. Searle (1990)</span> roasts his opponents, wondering</p>
    <b><i>
    <p>How could anyone have supposed that a computer simulation of a mental process must be the real thing?</p>
    </i></b>
    <p>Note it is not the <em>software</em> that becomes conscious. Searle describes the folly in mistaking software for the hardware in which consciousness happens (<span class="citation">J. R. Searle (1980)</span>)</p>
    <b><i>
    <p>No one would suppose that we could produce milk and sugar by running a computer simulation of the formal sequences in lactation and photosynthesis, but where the mind is concerned many people are willing to believe in such a miracle because of a deep and abiding dualism: the mind they suppose is a matter of formal processes and is independent of quite specific material causes in the way that milk and sugar are not.</p>
    </i></b>
    <p>What has been so badly misunderstood or what is being objected to? The thought experiment itself can be summarised like so: there is a man in a closed-off room who does not know Chinese. However, there has been given him a book with proper responses to phrases he receives from a person outside who is ignorant of the entire system except for a slot by which to pass such messages. The man in the box writes the Chinese replies to phrases the outside person passed in. Searle completes the description with essential, though potentially overlooked, details from Searle (1990, p. 26). The “I” he refers to is himself as the man inside the box who knows no Chinese.</p>
    <b><i>
    <p>Now, the rule book is the “computer program.” The people who wrote it were the “programmers,” and I am the “computer.” The baskets full of symbols are the “data base,” the small bunches that are handed in to me are “questions” and the bunches I then hand out are “answers.”</p>
    </i></b>
    <h1 id="iit-as-a-measure-of-consciousness"><span class="header-section-number">2</span> IIT as a Measure of Consciousness</h1>
    <p>Let’s accept Searle’s main points that it is only machines that become conscious, and thus imagine building such a machine and operating it. How would we monitor its progress? How could it monitor its own progress? Let’s keep it simple and assume it would not have the ability to talk, only to be conscious. It probably would have few sense organisms other than the sense of consciousness, as that would be sufficient for consciousness. It may look like the <a href="http://www.forbes.com/sites/gregsatell/2016/04/06/ibm-has-created-a-revolutionary-new-model-for-computing-the-human-brain/#23c0f6c94a15">silicon chip based on brain physiology</a> that unveiled by IBM in April.</p>
    <p>Information Integration Theory (IIT) contributes to studies of consciousness by providing a measure for consciousness. The measure is denoted <span class="math inline"><em>Φ</em><sup><em>m</em><em>a</em><em>x</em></sup></span>, and can be simply thought of as highest when both “integration” of information and magnitude of information states are maximized <span class="citation">G. Tononi et al. (2015)</span>. This contribution of a measure of consciousness is like providing the geodesic distance to geography. In striving to build a man-mande machine where consciousness is possible, it would be necessary to calculate consciousness to measure progress. Tononi is a co-author of an article that measures consciousness in human versions of such a machine where only consciousness might be active: a person’s brain in a vegetative state. In that case, IIT is not measured directly, but instead measures the perturbational complexity index (PCI). PCI is a measure of a signal generated by the electricortical responses to transcranial magnetic stimulation (TMS), which is the disruption of normal cognitive functions by way of sufficiently strong and focused magnetic fields. They performed this experiment on individuals across various qualitative levels of consciousness, e.g. in NREM or REM sleep, awake, under the effect of a variety of anesthetics, etc., and showed that the PCI correlated with those various states <span class="citation">A. G. Casali et al. (2013)</span>.</p>
    <h1 id="at-the-dawn-of-the-conscious-machines"><span class="header-section-number">3</span> At the dawn of the conscious machines…</h1>
    <p>Searle emphasizes the fact that “only machines can think”. The fact is any man-made machine that achieves consciousness may start being conscious before it could tell us it’s conscious, much like mammal newborns. In this case, such theoretically-sound data measures will enable us to somehow observe the machine itself, calculate <span class="math inline"><em>Φ</em><sup><em>m</em><em>a</em><em>x</em></sup></span> or a suitable surrogate, and detect consciousness when it arises.</p>
    <h1 id="references" class="unnumbered">References</h1>
    <div id="refs" class="references">
    <div id="ref-Casali2013">
    <p>Casali, A. G., Gosseries, O., Rosanova, M., Boly, M., Sarasso, S., Casali, K. R., … Massimini, M. (2013). A Theoretically Based Index of Consciousness Independent of Sensory Processing and Behavior. <em>Science Translational Medicine</em>, <em>5</em>(198), 198ra105–198ra105. <a href="http://doi.org/10.1126/scitranslmed.3006294" class="uri">http://doi.org/10.1126/scitranslmed.3006294</a></p>
    </div>
    <div id="ref-Searle1980">
    <p>Searle, J. R. (1980). Minds, Brains, and Programs. <em>Behavioral and Brain Sciences</em>.</p>
    </div>
    <div id="ref-Searle1990">
    <p>Searle, J. R. (1990). Is the brain’s mind a computer program? <a href="http://doi.org/10.1038/scientificamerican0190-26" class="uri">http://doi.org/10.1038/scientificamerican0190-26</a></p>
    </div>
    <div id="ref-Tononi2015">
    <p>Tononi, G., Koch, C., Koch, C., Baars, B., Gage, N., Dehaene, S., … Koch, C. (2015). Consciousness: here, there and everywhere? <em>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</em>, <em>370</em>(1668), 200–227. <a href="http://doi.org/10.1098/rstb.2014.0167" class="uri">http://doi.org/10.1098/rstb.2014.0167</a></p>
    </div>
    </div>
</div>
</body>
</html>
